---
author: [Yuan Zhou, Weiwei Gong, Vinita Subramanian, Teck Hua Lee, Tirthankar Lahiri, Shasank Chavan, Sebastian DeLaHoz, Roger Ford, Rohan Aggarwal, Mark Hornick, Malavika S P, Harichandan Roy, George Krupka, Doug Hood, Dinesh Das, David Jiang, Boriana Milenova, Bonnie Xia, Aurosish Mishra, Angela Amor, Agnivo Saha, Aleksandra Czarlinska, Ramya P, Usha Krishnamurthy, Tulika Das, Suresh Rajan, Sarika Surampudi, Sarah Hirschfeld, Prakash Jashnani, Jody Glover, Jessica True, Mamata Basapur, Maitreyee Chaliha, Gunjan Jain, Frederick Kush, Douglas Williams, Binika Kumar, Jean-Francois Verrier]
publisherinformation: May2024
---

# Vector Distance Metrics

Measuring distances in a vector space is at the heart of identifying the most relevant results for a given query vector. That process is very different from the well-known keyword filtering in the relational database world.

When working with vectors, there are several ways you can calculate distances to determine how similar, or dissimilar, two vectors are. Each distance metric is computed using different mathematical formulas. The time it takes to calculate those distances grows with the number of vector dimensions, which can go into thousands of dimensions. Generally it's best to match the distance metric you use to the one that was used to train your vector embedding model.

-   **[Euclidean and Euclidean Squared Distances](GUID-BA22C69B-CC35-4CA4-A845-C9098D254511.md)**  
Euclidean distance reflects the distance between each of the vectors' coordinates being comparedâ€”basically the straight-line distance between two vectors. This is calculated using the Pythagorean theorem applied to the vector's coordinates `(SQRT(SUM((xi-yi)2)))`.
-   **[Cosine Similarity](GUID-FFF09EC7-29D3-49C1-9F85-815832BC4B72.md)**  
One of the most widely used similarity metric, especially in natural language processing \(NLP\), is cosine similarity, which measures the cosine of the angle between two vectors.
-   **[Dot Product Similarity](GUID-1BA7C147-041E-4073-A211-4D61287036AF.md)**  
The dot product similarity of two vectors can be viewed as multiplying the size of each vector by the cosine of their angle. The corresponding geometrical interpretation of this definition is equivalent to multiplying the size of one of the vectors by the size of the projection of the second vector onto the first one, or vice versa.
-   **[Manhattan Distance](GUID-5965084E-E8E5-4EEB-A86E-025B7ED8DC02.md)**  
This metric is calculated by summing the distance between the dimensions of the two vectors that you want to compare.
-   **[Hamming Similarity](GUID-EBA30C96-B909-44E6-8561-CDB34D24601F.md)**  
The Hamming distance between two vectors represents the number of dimensions where they differ.

**Parent topic:**[Vector Distance Functions](GUID-8667D062-8084-4E55-8BD7-2C84E05F52FA.md)

